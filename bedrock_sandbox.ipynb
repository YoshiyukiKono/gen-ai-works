{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YoshiyukiKono/gen-ai-works/blob/main/bedrock_sandbox.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6715bc2b",
      "metadata": {
        "id": "6715bc2b"
      },
      "source": [
        "# AWS Bedrock + LangChain\n",
        "\n",
        "https://python.langchain.com/v0.1/docs/integrations/llms/bedrock/\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "761d9b70",
      "metadata": {
        "id": "761d9b70"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "Make sure you have a vector-capable Astra database (get one for free at [astra.datastax.com](https://astra.datastax.com)):\n",
        "\n",
        "- You will be asked to provide the **Database ID** for your Astra DB instance (see [here](https://awesome-astra.github.io/docs/pages/astra/faq/#where-should-i-find-a-database-identifier) for details);\n",
        "- Ensure you have an **Access Token** for your database with role _Database Administrator_ (see [here](https://awesome-astra.github.io/docs/pages/astra/create-token/) for details).\n",
        "\n",
        "Likewise, you will need the credentials to your Amazon Web Services identity, with access to **Amazon Bedrock**."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atDINpHcq0VF",
        "outputId": "b7e90042-7a9c-4c3d-86c3-da89da963b7a"
      },
      "id": "atDINpHcq0VF",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.38 (from langchain)\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.52 (from langchain)\n",
            "  Downloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.57-py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.52->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.52->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.6 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.20 langchain-community-0.0.38 langchain-core-0.1.52 langchain-text-splitters-0.0.1 langsmith-0.1.57 marshmallow-3.21.2 mypy-extensions-1.0.0 orjson-3.10.3 packaging-23.2 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade boto3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0w5Lc2prFHP",
        "outputId": "d430dd1c-02ad-4deb-f1e5-1ace73304afb"
      },
      "id": "B0w5Lc2prFHP",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting boto3\n",
            "  Downloading boto3-1.34.105-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.35.0,>=1.34.105 (from boto3)\n",
            "  Downloading botocore-1.34.105-py3-none-any.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.105->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.105->boto3) (2.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.105->boto3) (1.16.0)\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.34.105 botocore-1.34.105 jmespath-1.0.1 s3transfer-0.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7kzn7OjrT3C",
        "outputId": "77322dda-f027-41db-fa81-aa99102c8132"
      },
      "id": "h7kzn7OjrT3C",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir .aws"
      ],
      "metadata": {
        "id": "bfWfF0q4tAri"
      },
      "id": "bfWfF0q4tAri",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Input your AWS Access Key ID\n",
        "os.environ[\"AWS_ACCESS_KEY_ID\"] = getpass(\"Your AWS Access Key ID:\")\n",
        "# Input your AWS Secret Access Key\n",
        "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = getpass(\"Your AWS Secret Access Key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPUD5MRUtHyM",
        "outputId": "99129e56-11e3-4812-d265-3404844d50a2"
      },
      "id": "PPUD5MRUtHyM",
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your AWS Access Key ID:··········\n",
            "Your AWS Secret Access Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input your AWS Session Token\n",
        "os.environ[\"AWS_SESSION_TOKEN\"] = getpass(\"Your AWS Session Token:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoFWg2GR9Osq",
        "outputId": "dcbc53d8-e623-4695-add1-3fa484e7e714"
      },
      "id": "QoFWg2GR9Osq",
      "execution_count": 27,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your AWS Session Token:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del os.environ['AWS_SESSION_TOKEN']"
      ],
      "metadata": {
        "id": "oErtqDfE-Njk"
      },
      "id": "oErtqDfE-Njk",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "from langchain.embeddings import BedrockEmbeddings\n",
        "from langchain.llms import Bedrock\n",
        "\n",
        "bedrock_runtime = boto3.client(\"bedrock-runtime\", \"us-west-2\")\n",
        "bedrock_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\",\n",
        "                                       client=bedrock_runtime)"
      ],
      "metadata": {
        "id": "JmUdExtmtnzb"
      },
      "id": "JmUdExtmtnzb",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedded = bedrock_embeddings.embed_query(\"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "NDasRo26xDM6",
        "outputId": "b42188a2-d241-4bea-ea2f-4a52ea1d346e"
      },
      "id": "NDasRo26xDM6",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Error raised by inference endpoint: An error occurred (UnrecognizedClientException) when calling the InvokeModel operation: The security token included in the request is invalid.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/bedrock.py\u001b[0m in \u001b[0;36m_embedding_func\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;31m# invoke bedrock API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             response = self.client.invoke_model(\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1020\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mClientError\u001b[0m: An error occurred (UnrecognizedClientException) when calling the InvokeModel operation: The security token included in the request is invalid.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-88b08c6f10e3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbedrock_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/bedrock.py\u001b[0m in \u001b[0;36membed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mEmbeddings\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \"\"\"\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embedding_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/bedrock.py\u001b[0m in \u001b[0;36m_embedding_func\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse_body\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"embedding\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error raised by inference endpoint: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_normalize_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error raised by inference endpoint: An error occurred (UnrecognizedClientException) when calling the InvokeModel operation: The security token included in the request is invalid."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://qiita.com/saurus12/items/fa882dcd23def9c5ac52"
      ],
      "metadata": {
        "id": "eDJoDt5ysl1C"
      },
      "id": "eDJoDt5ysl1C"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "\n",
        "CREDENTIALS_FILE_PATH = \"/content/.aws/credentials\"\n",
        "os.environ['AWS_SHARED_CREDENTIALS_FILE'] = CREDENTIALS_FILE_PATH\n"
      ],
      "metadata": {
        "id": "Z4X5zSINsm94"
      },
      "id": "Z4X5zSINsm94",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "18548e31",
      "metadata": {
        "id": "18548e31"
      },
      "source": [
        "## Set up your Python environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "042f832e",
      "metadata": {
        "tags": [],
        "id": "042f832e",
        "outputId": "3ba2d260-9dc3-401d-cbbb-e7016668928b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m943.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.2/548.2 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.9/18.9 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --quiet \\\n",
        "  \"cassio>=0.1.3\" \\\n",
        "  \"langchain==0.0.249\" \\\n",
        "  \"boto3==1.28.62\" \\\n",
        "  \"botocore==1.31.62\" \\\n",
        "  \"cohere==4.37\" \\\n",
        "  \"openai==1.3.7\" \\\n",
        "  \"tiktoken==0.5.2\" \\\n",
        "  \"awscli==1.29.62\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c840842",
      "metadata": {
        "id": "6c840842"
      },
      "source": [
        "## Import needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b243d1b4",
      "metadata": {
        "tags": [],
        "id": "b243d1b4"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import sys\n",
        "from getpass import getpass\n",
        "\n",
        "\n",
        "import boto3\n",
        "#import cassio\n",
        "\n",
        "from langchain.embeddings import BedrockEmbeddings\n",
        "from langchain.llms import Bedrock\n",
        "from langchain.vectorstores import Cassandra\n",
        "from langchain.schema import Document\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.document_loaders import TextLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fccce0c2",
      "metadata": {
        "id": "fccce0c2"
      },
      "source": [
        "## Astra DB Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9b0a92b-f9ce-4810-a8ef-5741b2449b18",
      "metadata": {
        "tags": [],
        "id": "a9b0a92b-f9ce-4810-a8ef-5741b2449b18",
        "outputId": "6e1bbebd-a626-414a-f061-8a58eb949ea9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Astra DB ID ('0123abcd-'):ebe83fdc-873b-4c91-b923-80b6c5e82f27\n",
            "Enter your Astra DB Token ('AstraCS:...'):··········\n",
            "Enter your keyspace name (optional, default keyspace used if not provided):bedrock\n"
          ]
        }
      ],
      "source": [
        "ASTRA_DB_ID = input(\"Enter your Astra DB ID ('0123abcd-'):\")\n",
        "ASTRA_DB_APPLICATION_TOKEN = getpass(\"Enter your Astra DB Token ('AstraCS:...'):\")\n",
        "ASTRA_DB_KEYSPACE = input(\"Enter your keyspace name (optional, default keyspace used if not provided):\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a066f378-8fdb-4d4b-a7b1-bf685fbfd413",
      "metadata": {
        "tags": [],
        "id": "a066f378-8fdb-4d4b-a7b1-bf685fbfd413",
        "outputId": "021f82fc-bafb-4325-9c2d-e86ce6c431ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for ebe83fdc-873b-4c91-b923-80b6c5e82f27-us-east-2.db.astra.datastax.com:29042:36887b67-fd8a-4452-9d77-6c6fe16ea1b1. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for ebe83fdc-873b-4c91-b923-80b6c5e82f27-us-east-2.db.astra.datastax.com:29042:36887b67-fd8a-4452-9d77-6c6fe16ea1b1. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "ERROR:cassandra.connection:Closing connection <AsyncoreConnection(140568702113904) ebe83fdc-873b-4c91-b923-80b6c5e82f27-us-east-2.db.astra.datastax.com:29042:36887b67-fd8a-4452-9d77-6c6fe16ea1b1> due to protocol error: Error from server: code=000a [Protocol error] message=\"Beta version of the protocol used (5/v5-beta), but USE_BETA flag is unset\"\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for ebe83fdc-873b-4c91-b923-80b6c5e82f27-us-east-2.db.astra.datastax.com:29042:36887b67-fd8a-4452-9d77-6c6fe16ea1b1. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        }
      ],
      "source": [
        "cassio.init(\n",
        "    token=ASTRA_DB_APPLICATION_TOKEN,\n",
        "    database_id=ASTRA_DB_ID,\n",
        "    keyspace=ASTRA_DB_KEYSPACE if ASTRA_DB_KEYSPACE else None,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33c674f1",
      "metadata": {
        "id": "33c674f1"
      },
      "source": [
        "## AWS Credentials Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3219cb02-f955-4fb3-85af-3f149868958a",
      "metadata": {
        "id": "3219cb02-f955-4fb3-85af-3f149868958a"
      },
      "source": [
        "_Note_: in the following cells you will be asked to explicitly provide the credentials to your AWS account. These are set as environment variables for usage by the subsequent `boto3` calls. Please refer to [boto3's documentation](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html) on the possible ways to supply your credentials in a more production-like environment.\n",
        "\n",
        "In particular, if you are running this notebook in **Amazon SageMaker Studio**, please note that it is sufficient to add the Bedrock policy to your SageMaker role, as outlined at [this link](https://github.com/aws-samples/amazon-bedrock-workshop#enable-aws-iam-permissions-for-bedrock), to access the Bedrock services. In that case you can skip the following three setup cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "ccbb76ea",
      "metadata": {
        "tags": [],
        "id": "ccbb76ea",
        "outputId": "86bb1905-cc30-40b3-fbe3-e8d150bbc7b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your AWS Access Key ID:··········\n"
          ]
        }
      ],
      "source": [
        "# Input your AWS Access Key ID\n",
        "os.environ[\"AWS_ACCESS_KEY_ID\"] = getpass(\"Your AWS Access Key ID:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f93c873d",
      "metadata": {
        "tags": [],
        "id": "f93c873d",
        "outputId": "18a238f3-d50b-451c-d294-f67eeeec978e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your AWS Secret Access Key:··········\n"
          ]
        }
      ],
      "source": [
        "# Input your AWS Secret Access Key\n",
        "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = getpass(\"Your AWS Secret Access Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "737249f5",
      "metadata": {
        "tags": [],
        "id": "737249f5",
        "outputId": "99701422-8c87-4d29-f425-bca3fd9a2441",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your AWS Session Token:··········\n"
          ]
        }
      ],
      "source": [
        "# Input your AWS Session Token\n",
        "os.environ[\"AWS_SESSION_TOKEN\"] = getpass(\"Your AWS Session Token:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4388ac1d",
      "metadata": {
        "id": "4388ac1d"
      },
      "source": [
        "## Set up AWS Bedrock objects"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bedrock_runtime = boto3.client(\"bedrock-runtime\", \"ap-northeast-1\")"
      ],
      "metadata": {
        "id": "CB1Fq3W0C9XK"
      },
      "id": "CB1Fq3W0C9XK",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "d65c46f0",
      "metadata": {
        "tags": [],
        "id": "d65c46f0"
      },
      "outputs": [],
      "source": [
        "bedrock_runtime = boto3.client(\"bedrock-runtime\", \"us-west-2\")\n",
        "bedrock_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\",\n",
        "                                       client=bedrock_runtime)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vLr3KBBrC80t"
      },
      "id": "vLr3KBBrC80t"
    },
    {
      "cell_type": "markdown",
      "id": "29d9f48b",
      "metadata": {
        "id": "29d9f48b"
      },
      "source": [
        "## Set up the Vector Store\n",
        "\n",
        "This command will create a suitable table in your database if it does not exist yet:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29d9f48c",
      "metadata": {
        "tags": [],
        "id": "29d9f48c"
      },
      "outputs": [],
      "source": [
        "vector_store = Cassandra(\n",
        "    embedding=bedrock_embeddings,\n",
        "    table_name=\"shakespeare_act5\",\n",
        "    session=None,  # <-- meaning: use the global defaults from cassio.init()\n",
        "    keyspace=None,  # <-- meaning: use the global defaults from cassio.init()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6af24199",
      "metadata": {
        "id": "6af24199"
      },
      "source": [
        "## Populate the database\n",
        "\n",
        "Add lines for the text of \"Romeo and Astra\", Scene 5, Act 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dab5114",
      "metadata": {
        "tags": [],
        "id": "1dab5114",
        "outputId": "34331609-e794-4452-adc3-d8a8df6f7935",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 75985  100 75985    0     0   252k      0 --:--:-- --:--:-- --:--:--  252k\n"
          ]
        }
      ],
      "source": [
        "# retrieve the text of a scene from act 5 of Romeo and Astra.\n",
        "# Juliet's name was changed to Astra to prevent the LLM from \"cheating\" when providing an answer.\n",
        "! mkdir -p \"texts\"\n",
        "! curl \"https://raw.githubusercontent.com/awesome-astra/docs/main/docs/pages/aiml/aws/bedrock_resources/romeo_astra.json\" \\\n",
        "    --output \"texts/romeo_astra.json\"\n",
        "input_lines = json.load(open(\"texts/romeo_astra.json\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cb6b732",
      "metadata": {
        "id": "4cb6b732"
      },
      "source": [
        "Next, you'll populate the database with the lines from the play.\n",
        "This can take a couple of minutes, please be patient.  In total there are 321 lines.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bae5520",
      "metadata": {
        "tags": [],
        "id": "7bae5520",
        "outputId": "98c6e0fc-fc3b-4a14-8135-049208280441",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding 321 documents ... Done.\n"
          ]
        }
      ],
      "source": [
        "input_documents = []\n",
        "\n",
        "for input_line in input_lines:\n",
        "    if (input_line[\"ActSceneLine\"] != \"\"):\n",
        "        (act, scene, line) = input_line[\"ActSceneLine\"].split(\".\")\n",
        "        location = \"Act {}, Scene {}, Line {}\".format(act, scene, line)\n",
        "        metadata = {\"act\": act, \"scene\": scene, \"line\": line}\n",
        "    else:\n",
        "        location = \"\"\n",
        "        metadata = {}\n",
        "    quote_input = \"{} : {} : {}\".format(location, input_line[\"Player\"], input_line[\"PlayerLine\"])\n",
        "    input_document = Document(page_content=quote_input, metadata=metadata)\n",
        "    input_documents.append(input_document)\n",
        "\n",
        "print(f\"Adding {len(input_documents)} documents ... \", end=\"\")\n",
        "vector_store.add_documents(documents=input_documents, batch_size=50)\n",
        "print(\"Done.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d162c2d1-188e-43f0-b1c3-342b80641060",
      "metadata": {
        "id": "d162c2d1-188e-43f0-b1c3-342b80641060"
      },
      "source": [
        "## Answer questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5332b838-6c1f-40f4-a29e-2b2d0250f408",
      "metadata": {
        "tags": [],
        "id": "5332b838-6c1f-40f4-a29e-2b2d0250f408"
      },
      "outputs": [],
      "source": [
        "prompt_template_str = \"\"\"Human: Use the following pieces of context to provide a concise answer to the question at the end.\n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "\n",
        "<context>\n",
        "{context}\n",
        "</context\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Assistant:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(prompt_template_str)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template_str = \"\"\"Human: {question}\n",
        "\n",
        "Assistant:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(prompt_template_str)"
      ],
      "metadata": {
        "id": "T8uCaZrPAWoP"
      },
      "id": "T8uCaZrPAWoP",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ea67346b-d5ca-433d-858e-5c21397f9de5",
      "metadata": {
        "tags": [],
        "id": "ea67346b-d5ca-433d-858e-5c21397f9de5"
      },
      "source": [
        "We choose to use the following LLM model (see [this page](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html#model-parameters-general) for more info):"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"anthropic.claude\""
      ],
      "metadata": {
        "id": "_wo5H_9vIzWI"
      },
      "id": "_wo5H_9vIzWI",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"anthropic.claude-v2:1\""
      ],
      "metadata": {
        "id": "q9XBwMmYJJ5o"
      },
      "id": "q9XBwMmYJJ5o",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ee8b2ee0-f9bf-4ada-8fde-7d917d89c6fa",
      "metadata": {
        "tags": [],
        "id": "ee8b2ee0-f9bf-4ada-8fde-7d917d89c6fa"
      },
      "outputs": [],
      "source": [
        "model_id = \"anthropic.claude-v2\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4081fd78-1710-4a42-a942-a14f652c854d",
      "metadata": {
        "id": "4081fd78-1710-4a42-a942-a14f652c854d"
      },
      "source": [
        "Here the question-answering function is set up, implementing the RAG pattern:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "4e82ef49-ffec-4429-bcc2-ea09f50333cd",
      "metadata": {
        "tags": [],
        "id": "4e82ef49-ffec-4429-bcc2-ea09f50333cd"
      },
      "outputs": [],
      "source": [
        "req_accept = \"application/json\"\n",
        "req_content_type = \"application/json\"\n",
        "\n",
        "# This, created from the vector store, will fetch the top relevant documents given a text query\n",
        "#retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
        "\n",
        "def answer_question(question: str, verbose: bool = False) -> str:\n",
        "    if verbose:\n",
        "        print(f\"\\n[answer_question] Question: {question}\")\n",
        "    # Retrieval of the most relevant stored documents from the vector store:\n",
        "    #context_docs = retriever.get_relevant_documents(question)\n",
        "    #context = \"\\n\".join(doc.page_content for doc in context_docs)\n",
        "    #if verbose:\n",
        "    #    print(\"\\n[answer_question] Context:\")\n",
        "    #    print(context)\n",
        "    # Filling the prompt template with the current values\n",
        "    llm_prompt_str = prompt.format(\n",
        "        question=question,\n",
        "        #context=context,\n",
        "    )\n",
        "    # Invocation of the Amazon Bedrock LLM for text completion -- ultimately obtaining the answer\n",
        "    llm_body = json.dumps({\"prompt\": llm_prompt_str, \"max_tokens_to_sample\": 500})\n",
        "    llm_response = bedrock_runtime.invoke_model(\n",
        "        body=llm_body,\n",
        "        modelId=model_id,\n",
        "        accept=req_accept,\n",
        "        contentType=req_content_type,\n",
        "    )\n",
        "    llm_response_body = json.loads(llm_response[\"body\"].read())\n",
        "    answer = llm_response_body[\"completion\"].strip()\n",
        "    if verbose:\n",
        "        print(f\"\\n[answer_question] Answer: {answer}\\n\")\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_answer = answer_question(\"Who are you?\")\n",
        "print(\"=\" * 60)\n",
        "print(my_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrtK2MXdANy7",
        "outputId": "9133b195-39f0-462e-84fc-753bab04d161"
      },
      "id": "KrtK2MXdANy7",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "I'm Claude, an AI assistant created by Anthropic.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "599d8856-921e-4bf4-8979-ff54b13de6d5",
      "metadata": {
        "tags": [],
        "id": "599d8856-921e-4bf4-8979-ff54b13de6d5",
        "outputId": "50e35724-1a23-4e97-efe0-0b2ed70f80ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AccessDeniedException",
          "evalue": "An error occurred (AccessDeniedException) when calling the InvokeModel operation: User: arn:aws:iam::128851615533:user/BedrockUser is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-v2 because no identity-based policy allows the bedrock:InvokeModel action",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAccessDeniedException\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-0656b9352920>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Who dies in the story?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_answer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-439f07356e14>\u001b[0m in \u001b[0;36manswer_question\u001b[0;34m(question, verbose)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Invocation of the Amazon Bedrock LLM for text completion -- ultimately obtaining the answer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mllm_body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mllm_prompt_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"max_tokens_to_sample\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     llm_response = bedrock_runtime.invoke_model(\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm_body\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mmodelId\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m                 )\n\u001b[1;32m    564\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1019\u001b[0m             )\n\u001b[1;32m   1020\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAccessDeniedException\u001b[0m: An error occurred (AccessDeniedException) when calling the InvokeModel operation: User: arn:aws:iam::128851615533:user/BedrockUser is not authorized to perform: bedrock:InvokeModel on resource: arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-v2 because no identity-based policy allows the bedrock:InvokeModel action"
          ]
        }
      ],
      "source": [
        "my_answer = answer_question(\"Who dies in the story?\")\n",
        "print(\"=\" * 60)\n",
        "print(my_answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db71cc88-61e3-42e5-802b-4ba4eaa795b4",
      "metadata": {
        "id": "db71cc88-61e3-42e5-802b-4ba4eaa795b4"
      },
      "source": [
        "Let's take a look at the RAG process piece-wise:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fbeaf2d-f589-4d04-8447-4b876375f5b1",
      "metadata": {
        "tags": [],
        "id": "6fbeaf2d-f589-4d04-8447-4b876375f5b1",
        "outputId": "db925815-57e0-474b-b080-5d253b75d8ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[answer_question] Question: Who dies in the story?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[answer_question] Context:\n",
            "Act 5, Scene 3, Line 184 : First Watchman : And Astra bleeding, warm, and newly dead,\n",
            "Act 5, Scene 3, Line 300 : PRINCE : Came to this vault to die, and lie with Astra.\n",
            "Act 5, Scene 3, Line 282 : BALTHASAR : I brought my master news of Astra's death,\n",
            "Act 5, Scene 3, Line 206 : First Watchman : Warm and new kill'd.\n",
            "Act 5, Scene 3, Line 205 : First Watchman : And Romeo dead, and Astra, dead before,\n",
            "\n",
            "[answer_question] Answer: Based on the provided context, it seems that Astra and Romeo both die in the story. The watchman finds Astra dead in the vault, and later finds Romeo dead there as well. Balthasar brings news to Romeo that Astra is dead, which leads Romeo to go to the vault to die beside Astra. So the characters who die are Astra and Romeo.\n",
            "\n",
            "============================================================\n",
            "Based on the provided context, it seems that Astra and Romeo both die in the story. The watchman finds Astra dead in the vault, and later finds Romeo dead there as well. Balthasar brings news to Romeo that Astra is dead, which leads Romeo to go to the vault to die beside Astra. So the characters who die are Astra and Romeo.\n"
          ]
        }
      ],
      "source": [
        "my_answer = answer_question(\"Who dies in the story?\", verbose=True)\n",
        "print(\"=\" * 60)\n",
        "print(my_answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "715ba03a-66d1-47fe-9a8e-6b2713ddd0f9",
      "metadata": {
        "id": "715ba03a-66d1-47fe-9a8e-6b2713ddd0f9"
      },
      "source": [
        "### Interactive QA session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fe0df9c-b24d-4f35-aee4-8bef2dd1e1a6",
      "metadata": {
        "tags": [],
        "id": "9fe0df9c-b24d-4f35-aee4-8bef2dd1e1a6",
        "outputId": "df47ddeb-9adc-4dca-c118-f3a56c421451",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a question (empty to quit):Who kills Romeo?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer ==> Based on the provided context, I don't have enough information to determine who kills Romeo. The lines mention that Romeo is dead, but do not specify who killed him.\n",
            "Enter a question (empty to quit):\n",
            "[User, AI exeunt]\n"
          ]
        }
      ],
      "source": [
        "user_question = \"\"\n",
        "while True:\n",
        "    user_question = input(\"Enter a question (empty to quit):\").strip()\n",
        "    if user_question:\n",
        "        print(f\"Answer ==> {answer_question(user_question)}\")\n",
        "    else:\n",
        "        print(\"[User, AI exeunt]\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Japanese Trial"
      ],
      "metadata": {
        "id": "rumUqf8yfMLW"
      },
      "id": "rumUqf8yfMLW"
    },
    {
      "cell_type": "code",
      "source": [
        "my_answer = answer_question(\"物語の中で死んだのは誰?\", verbose=True)\n",
        "print(\"=\" * 60)\n",
        "print(my_answer)"
      ],
      "metadata": {
        "id": "kveETQ4efVEY",
        "outputId": "7e5dd7a0-bf0e-4880-8def-795772393e4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "kveETQ4efVEY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[answer_question] Question: 物語の中で死んだのは誰?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[answer_question] Context:\n",
            "Act 5, Scene 3, Line 320 : PRINCE : For never was a story of more woe\n",
            "Act 5, Scene 3, Line 51 : PARIS : It is supposed, the fair creature died,\n",
            "Act 5, Scene 3, Line 318 : PRINCE : Go hence, to have more talk of these sad things,\n",
            "Act 5, Scene 3, Line 207 : PRINCE : Search, seek, and know how this foul murder comes.\n",
            "Act 5, Scene 3, Line 303 : PRINCE : That heaven finds means to kill your joys with love.\n",
            "\n",
            "[answer_question] Answer: コンテキストから判断すると、Julietが死んだと考えられます。Act 5, Scene 3, Line 51でParisが\"fair creature\"が死んだと言っています。これはJulietを指していると思われ、物語の中でJulietが死んだことが示唆されています。正確にはコンテキストからは判断できませんが、Julietの死を示唆していると考えられます。\n",
            "\n",
            "============================================================\n",
            "コンテキストから判断すると、Julietが死んだと考えられます。Act 5, Scene 3, Line 51でParisが\"fair creature\"が死んだと言っています。これはJulietを指していると思われ、物語の中でJulietが死んだことが示唆されています。正確にはコンテキストからは判断できませんが、Julietの死を示唆していると考えられます。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_answer = answer_question(\"城の見回りをしているのは誰?\", verbose=True)\n",
        "print(\"=\" * 60)\n",
        "print(my_answer)"
      ],
      "metadata": {
        "id": "J-QV8TtsfqSS",
        "outputId": "093100a4-f0ec-43bd-b4da-d1e95b9c9e2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "J-QV8TtsfqSS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[answer_question] Question: 城の見回りをしているのは誰?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[answer_question] Context:\n",
            "Act 5, Scene 3, Line 2 : PARIS : Yet put it out, for I would not be seen.\n",
            "Act 5, Scene 3, Line 195 : Third Watchman : As he was coming from this churchyard side.\n",
            "Act 5, Scene 3, Line 176 : First Watchman : [Within]  Lead, boy: which way?\n",
            "Act 5, Scene 3, Line 6 : PARIS : Being loose, unfirm, with digging up of graves,\n",
            "Act 5, Scene 3, Line 284 : BALTHASAR : To this same place, to this same monument.\n",
            "\n",
            "[answer_question] Answer: 私は確信はありませんが、文脈から判断すると、見回りをしているのはwatchmanたちのようです。特に「First Watchman」と「Third Watchman」が登場しています。よって、見回りをしているのはおそらくwatchmanたちだと思いますが、はっきりとは言えません。申し訳ありませんが、確かな答えは分かりません。\n",
            "\n",
            "============================================================\n",
            "私は確信はありませんが、文脈から判断すると、見回りをしているのはwatchmanたちのようです。特に「First Watchman」と「Third Watchman」が登場しています。よって、見回りをしているのはおそらくwatchmanたちだと思いますが、はっきりとは言えません。申し訳ありませんが、確かな答えは分かりません。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f31c2d97",
      "metadata": {
        "id": "f31c2d97"
      },
      "source": [
        "## Additional resources\n",
        "\n",
        "To learn more about Amazon Bedrock, visit this page: [Introduction to Amazon Bedrock](https://github.com/aws-samples/amazon-bedrock-samples/tree/main/introduction-to-bedrock)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}